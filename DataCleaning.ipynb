{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa37a00b-d28d-434f-b79f-7664e2438997",
   "metadata": {},
   "source": [
    " # Data_Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "121135bd-2345-4420-90ed-779f845cde42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sohaibkhan\\AppData\\Local\\Temp\\ipykernel_2248\\904549278.py:4: DtypeWarning: Columns (1,2,3,7,8,9,11,12,13,14,17,18,19) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data=pd.read_csv(r\"C:\\Users\\sohaibkhan\\Documents\\Pakistan Largest Ecommerce Dataset.csv[1]\\Pakistan Largest Ecommerce Dataset.csv\")\n",
      "D:\\6 Semester\\anacondala\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "D:\\6 Semester\\anacondala\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: divide by zero encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 584524 entries, 0 to 584523\n",
      "Data columns (total 17 columns):\n",
      " #   Column             Non-Null Count   Dtype         \n",
      "---  ------             --------------   -----         \n",
      " 0   status             584509 non-null  object        \n",
      " 1   created_at         584524 non-null  datetime64[ns]\n",
      " 2   price              584524 non-null  float64       \n",
      " 3   qty_ordered        584524 non-null  float64       \n",
      " 4   category_name_1    584524 non-null  object        \n",
      " 5   discount_amount    584521 non-null  float64       \n",
      " 6   payment_method     584524 non-null  object        \n",
      " 7   Working Date       584524 non-null  datetime64[ns]\n",
      " 8   Year               584524 non-null  float64       \n",
      " 9   Month              584524 non-null  float64       \n",
      " 10  year               584524 non-null  float64       \n",
      " 11  month              584524 non-null  float64       \n",
      " 12  dayofweek          584524 non-null  float64       \n",
      " 13  is_weekend         584524 non-null  int32         \n",
      " 14  quarter            584524 non-null  float64       \n",
      " 15  discount_per_unit  584523 non-null  float64       \n",
      " 16  is_discounted      584524 non-null  int32         \n",
      "dtypes: datetime64[ns](2), float64(10), int32(2), object(3)\n",
      "memory usage: 75.8+ MB\n",
      "None\n",
      "status               15\n",
      "created_at            0\n",
      "price                 0\n",
      "qty_ordered           0\n",
      "category_name_1       0\n",
      "discount_amount       3\n",
      "payment_method        0\n",
      "Working Date          0\n",
      "Year                  0\n",
      "Month                 0\n",
      "year                  0\n",
      "month                 0\n",
      "dayofweek             0\n",
      "is_weekend            0\n",
      "quarter               0\n",
      "discount_per_unit     1\n",
      "is_discounted         0\n",
      "dtype: int64\n",
      "           status created_at     price  qty_ordered    category_name_1  \\\n",
      "0        complete 2016-07-01  7.576097     0.693147    Women's Fashion   \n",
      "1        canceled 2016-07-01  5.484797     0.693147  Beauty & Grooming   \n",
      "2        canceled 2016-07-01  7.804251     0.693147    Women's Fashion   \n",
      "3        complete 2016-07-01  5.888878     0.693147  Beauty & Grooming   \n",
      "4  order_refunded 2016-07-01  6.320768     1.098612            Soghaat   \n",
      "\n",
      "   discount_amount payment_method Working Date    Year  Month    year  month  \\\n",
      "0          0.00000            cod   2016-07-01  2016.0    7.0  2016.0    7.0   \n",
      "1          0.00000            cod   2016-07-01  2016.0    7.0  2016.0    7.0   \n",
      "2          0.00000            cod   2016-07-01  2016.0    7.0  2016.0    7.0   \n",
      "3          5.70711            cod   2016-07-01  2016.0    7.0  2016.0    7.0   \n",
      "4          0.00000            cod   2016-07-01  2016.0    7.0  2016.0    7.0   \n",
      "\n",
      "   dayofweek  is_weekend  quarter  discount_per_unit  is_discounted  \n",
      "0        4.0           0      3.0            0.00000              0  \n",
      "1        4.0           0      3.0            0.00000              0  \n",
      "2        4.0           0      3.0            0.00000              0  \n",
      "3        4.0           0      3.0            5.70711              1  \n",
      "4        4.0           0      3.0            0.00000              0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data=pd.read_csv(r\"C:\\Users\\sohaibkhan\\Documents\\Pakistan Largest Ecommerce Dataset.csv[1]\\Pakistan Largest Ecommerce Dataset.csv\")\n",
    "data.head(3)\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Drop completely irrelevant columns\n",
    "# -----------------------------\n",
    "drop_cols = [\n",
    "    \"Unnamed: 21\", \"Unnamed: 22\", \"Unnamed: 23\", \"Unnamed: 24\", \"Unnamed: 25\",\n",
    "    \"item_id\", \"sku\", \"increment_id\", \"Customer ID\",\n",
    "    \"sales_commission_code\", \"BI Status\", \"Customer Since\", \"M-Y\", \"FY\", \" MV \"\n",
    "]\n",
    "data.drop(columns=drop_cols, inplace=True, errors='ignore')\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Convert date columns to datetime\n",
    "# -----------------------------\n",
    "data['created_at'] = pd.to_datetime(data['created_at'], errors='coerce')\n",
    "data['Working Date'] = pd.to_datetime(data['Working Date'], errors='coerce')\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Extract useful date features BEFORE dropping the original dates\n",
    "# -----------------------------\n",
    "data['year'] = data['created_at'].dt.year\n",
    "data['month'] = data['created_at'].dt.month\n",
    "data['dayofweek'] = data['created_at'].dt.dayofweek\n",
    "data['is_weekend'] = data['dayofweek'].isin([5, 6]).astype(int)\n",
    "data['quarter'] = data['created_at'].dt.quarter\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Drop rows where target 'price' is missing\n",
    "# -----------------------------\n",
    "data = data[~data['price'].isnull()]\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Handle missing values for numeric columns\n",
    "# -----------------------------\n",
    "num_cols = ['qty_ordered', 'discount_amount', 'grand_total', 'year', 'month']\n",
    "for col in num_cols:\n",
    "    data[col] = data[col].fillna(0)\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Handle missing values for categorical columns\n",
    "# -----------------------------\n",
    "cat_cols = ['category_name_1', 'payment_method']\n",
    "for col in cat_cols:\n",
    "    data[col] = data[col].fillna('Unknown')\n",
    "\n",
    "# -----------------------------\n",
    "# 7. Feature Engineering\n",
    "# -----------------------------\n",
    "\n",
    "# Remove target leakage: drop grand_total because itâ€™s derived from price\n",
    "if 'grand_total' in data.columns:\n",
    "    data.drop(columns=['grand_total'], inplace=True)\n",
    "\n",
    "# Discount per unit (avoid division by zero)\n",
    "data['discount_per_unit'] = np.where(\n",
    "    data['qty_ordered'] > 0,\n",
    "    data['discount_amount'] / data['qty_ordered'],\n",
    "    0\n",
    ")\n",
    "\n",
    "# Is discounted (binary feature)\n",
    "data['is_discounted'] = (data['discount_amount'] > 0).astype(int)\n",
    "\n",
    "# Log-transform skewed features\n",
    "for col in ['price', 'qty_ordered', 'discount_amount', 'discount_per_unit']:\n",
    "    data[col] = np.log1p(data[col])\n",
    "\n",
    "# -----------------------------\n",
    "# 8. Final check\n",
    "# -----------------------------\n",
    "print(data.info())\n",
    "print(data.isnull().sum())\n",
    "print(data.head())\n",
    "\n",
    "# Save cleaned dataset\n",
    "data.to_csv(\"cleaned_ready_for_modeling.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3b4aee1-bc4e-410f-94ee-67f9a748c44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e321e7e-d898-4ece-8ab5-8ade17a2c043",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/sohaibkhan/Project1/Data/DataCleaning.pkl']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(data,\"C:/Users/sohaibkhan/Project1/Data/DataCleaning.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfd0665d-b036-42ad-8a9f-d02a22689475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features: ['status', 'created_at', 'price', 'qty_ordered', 'category_name_1', 'discount_amount', 'payment_method', 'Working Date', 'Year', 'Month', 'year', 'month', 'dayofweek', 'is_weekend', 'quarter', 'discount_per_unit', 'is_discounted']\n"
     ]
    }
   ],
   "source": [
    "print(\"Training features:\", list(data.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4647a4a0-c26c-4752-8a48-6b7e75d7ca1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
